{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Data Gathering and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-11-17 18:01:20.017154: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-17 18:01:20.441646: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 18:01:20.441684: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 18:01:20.445582: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 18:01:20.743784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-17 18:01:20.744922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 18:01:22.540321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing scikit-learn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nOnce upon a time, there were four friends na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nSure, here is a story about a character who ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nSure, here is a story about a character who ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nSure, here is a story about a person who fin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSure, here is a story set in a world where p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0  \\nOnce upon a time, there were four friends na...         0\n",
       "1  \\nSure, here is a story about a character who ...         0\n",
       "2  \\nSure, here is a story about a character who ...         0\n",
       "3  \\nSure, here is a story about a person who fin...         0\n",
       "4  \\nSure, here is a story set in a world where p...         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/unknown/AI Project/Combined.csv\", header=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data['Text']\n",
    "Y = data['Category']\n",
    "# vector = CountVectorizer()\n",
    "# counts = vector.fit_transform(data['Text'].values)\n",
    "# cat = data['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded format (for multi-class classification)\n",
    "Y_one_hot = tf.keras.utils.to_categorical(Y, num_classes=3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using various classification models and targetting 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB_Model = MultinomialNB()\n",
    "RFC_Model = RandomForestClassifier()\n",
    "# SVC_Model = SVC(probability=True)\n",
    "# KNC_Model = KNeighborsClassifier()\n",
    "# DTC_Model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the accuracy using 90/10 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest Algorithm has an accuracy of 81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "RFCtest = RFC_Model.fit(X_train_vectorized, Y_train)\n",
    "\n",
    "# RFCtest = RandomForestClassifier().fit(X_train,Y_train)\n",
    "acc_rfc = RFCtest.score(X_test_vectorized, Y_test)\n",
    "print('The Random Forest Algorithm has an accuracy of', acc_rfc*100)\n",
    "rf_predictions = RFC_Model.predict(X_test_vectorized)\n",
    "# 93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering text to predict the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:04:45.491847: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Build Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer for text\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "\n",
    "# Preprocess text using BERT preprocessing layer\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "\n",
    "# Encode processed text using BERT encoder\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Construct the neural network layers for classification\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "output_layer = tf.keras.layers.Dense(3, activation='softmax', name=\"output\")(l)  # Output layer for 3 classes\n",
    "\n",
    "# Build and compile the model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])  # Using accuracy as a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 275s 9s/step - loss: 0.8017 - accuracy: 0.6482\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 281s 9s/step - loss: 0.6683 - accuracy: 0.7223\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 291s 9s/step - loss: 0.6261 - accuracy: 0.7283\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 282s 9s/step - loss: 0.5969 - accuracy: 0.7381\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 283s 9s/step - loss: 0.5552 - accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb08c241150>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=5, batch_size=32)  # You might need to adjust epochs and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 70s 8s/step - loss: 0.5911 - accuracy: 0.7866\n",
      "Test accuracy: 78.65612506866455\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, Y_test)\n",
    "print(\"Test accuracy:\", results[1] * 100)  # results[1] contains accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 55s 7s/step\n",
      "Accuracy: 78.65612648221344%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "bert_predictions = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(bert_predictions, axis=1)\n",
    "Y_test_classes = np.argmax(Y_test, axis=1)\n",
    "accuracy = accuracy_score(Y_test_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n",
    "# print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 94.0711462450593%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature engineering: Add additional features (word count, average word length, etc.)\n",
    "\n",
    "data['Word_Count'] = data['Text'].apply(lambda x: len(str(x).split()))\n",
    "data['Avg_Word_Length'] = data['Text'].apply(lambda x: np.mean([len(word) for word in str(x).split()]))\n",
    "\n",
    "\n",
    "X_test_extra_features = data.loc[X_test.index, ['Word_Count', 'Avg_Word_Length']].values\n",
    "\n",
    "# Reconverting one-hot encoded Y_test back to 1D array of labels\n",
    "Y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Apply stacking ensemble using RFC and GLM predictions along with additional features\n",
    "final = np.hstack((rf_predictions, bert_predictions, X_test_extra_features))  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "meta_classifier = LogisticRegression(max_iter=10000)  \n",
    "# meta_classifier = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "\n",
    "meta_classifier.fit(final, Y_test_labels)  \n",
    "\n",
    "ensemble_predictions = meta_classifier.predict(final)\n",
    "\n",
    "ensemble_accuracy = accuracy_score(Y_test_labels, ensemble_predictions)\n",
    "print(f'Ensemble Model Accuracy: {ensemble_accuracy * 100}%')\n",
    "# print(f'Ensemble Model Accuracy: {ensemble_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
